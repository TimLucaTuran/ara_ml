{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Sasa Stacker Finding custom metasurface stacks to target transmission spectra. Functionality Fit: Input a spectrum as a .npy array and receive the stack parameters Train: Retrain the Neural Network Data: Generate training stacks based on pre-simulated single layers","title":"Home"},{"location":"#sasa-stacker","text":"Finding custom metasurface stacks to target transmission spectra.","title":"Sasa Stacker"},{"location":"#functionality","text":"Fit: Input a spectrum as a .npy array and receive the stack parameters Train: Retrain the Neural Network Data: Generate training stacks based on pre-simulated single layers","title":"Functionality"},{"location":"data_gen/","text":"usage: data_gen.py [-h] [-p PARAMS] [-n NUMBER_OF_BATCHES] [-db DATABASE] src dst positional arguments: src path to source directory containing .npy files dst path to destination batch directory optional arguments: -h, --help show this help message and exit -p PARAMS, --params PARAMS path to the .pickle file containing the smat parameters -n NUMBER_OF_BATCHES, --number-of-batches NUMBER_OF_BATCHES -db DATABASE, --database DATABASE sqlite database containing the adresses","title":"Data Generation"},{"location":"fit/","text":"Fit.py This is the main function taking a transmission spectrum as input and producing a metasurface stack as output. Usage Help to all scripts can be revived with the -h option. fit -h : fit.py [-h] [-m MODEL] [-db DATABASE] [-S SMATS] [-i INDEX] [-I] s positional arguments: s path to target spectrum .npy file optional arguments: -h, --help show this help message and exit -m MODEL, --model MODEL path to trained model model -db DATABASE, --database DATABASE sqlite database containing the adresses -S SMATS, --smats SMATS directory containing the smats for interpolation -i INDEX, --index INDEX -I, --interpolate The target spectrum has to be provided as a .npy array of shape L x 2 where L is the number of sampled wavelengths and the 2 contains X - and Y - polarization. The provided model stacker.h5 has been trained on a dataset with L = 160 Source Code [source] SingleLayerInterpolator sasa_stacker.fit.SingleLayerInterpolator(crawler, num_of_neigbours=6, power_faktor=2) This class takes parameters of a single layer meta surface and looks into the database for similar layers which have been simulated. It then interpolates these to get an approximation for the behaviour of a layer with the provided parameters. Arguments crawler : crawler obj. num_of_neigbours : int, how many similar layers should be considered for the interpolation power_faktor : int, exponent for inverse-distance-weight interpolation (IDW) loss sasa_stacker.fit.loss(arr, target_spec, p1, p2, p_stack, b1, b2, b_stack, crawler, plotter, sli, stp) This loss function is minimized by the scipy optimizer. It takes all the parameters of a stack, calculates the resulting transmission spectrum and compares it to the target. Additionally it checks if physical bounds are violated and adds params_bounds_distance() to the loss value. Arguments arr : array, the scipy optimizer needs the first argument to be an array with all the tuneable parameters. target_spec : Lx2 array p1 : dict, parameters of layer 1 p2 : dict, parameters of layer 2 p_stack : dict, parameters of the stack bounds : dict, {parameter: [lower bound, upper bound]} crawler : crawler object to access the db plotter : plotter object sli : SingleLayerInterpolator object Returns loss_val : float","title":"Fit"},{"location":"fit/#fitpy","text":"This is the main function taking a transmission spectrum as input and producing a metasurface stack as output.","title":"Fit.py"},{"location":"fit/#usage","text":"Help to all scripts can be revived with the -h option. fit -h : fit.py [-h] [-m MODEL] [-db DATABASE] [-S SMATS] [-i INDEX] [-I] s positional arguments: s path to target spectrum .npy file optional arguments: -h, --help show this help message and exit -m MODEL, --model MODEL path to trained model model -db DATABASE, --database DATABASE sqlite database containing the adresses -S SMATS, --smats SMATS directory containing the smats for interpolation -i INDEX, --index INDEX -I, --interpolate The target spectrum has to be provided as a .npy array of shape L x 2 where L is the number of sampled wavelengths and the 2 contains X - and Y - polarization. The provided model stacker.h5 has been trained on a dataset with L = 160","title":"Usage"},{"location":"fit/#source-code","text":"[source]","title":"Source Code"},{"location":"fit/#singlelayerinterpolator","text":"sasa_stacker.fit.SingleLayerInterpolator(crawler, num_of_neigbours=6, power_faktor=2) This class takes parameters of a single layer meta surface and looks into the database for similar layers which have been simulated. It then interpolates these to get an approximation for the behaviour of a layer with the provided parameters. Arguments crawler : crawler obj. num_of_neigbours : int, how many similar layers should be considered for the interpolation power_faktor : int, exponent for inverse-distance-weight interpolation (IDW)","title":"SingleLayerInterpolator"},{"location":"fit/#loss","text":"sasa_stacker.fit.loss(arr, target_spec, p1, p2, p_stack, b1, b2, b_stack, crawler, plotter, sli, stp) This loss function is minimized by the scipy optimizer. It takes all the parameters of a stack, calculates the resulting transmission spectrum and compares it to the target. Additionally it checks if physical bounds are violated and adds params_bounds_distance() to the loss value. Arguments arr : array, the scipy optimizer needs the first argument to be an array with all the tuneable parameters. target_spec : Lx2 array p1 : dict, parameters of layer 1 p2 : dict, parameters of layer 2 p_stack : dict, parameters of the stack bounds : dict, {parameter: [lower bound, upper bound]} crawler : crawler object to access the db plotter : plotter object sli : SingleLayerInterpolator object Returns loss_val : float","title":"loss"},{"location":"install/","text":"This package depends on googles tensorflow , which at the time of writing only supports python 3.5 - 3.7, so I recommend creating a virtual environment: $ python3.7 -m venv sasa-venv and activating it $ source sasa-venv/bin/activate Now clone this repository $ git clone https://github.com/TimLucaTuran/sasa_stacker cd into the repository and install the package $ cd sasa_stacker $ pip install . Test if everything worked $ cd sasa_stacker $ python fit.py data/test.npy","title":"Installation"},{"location":"train/","text":"Usage usage: train.py [-h] [-p PARAMS] [-s S_MATS] [-log LOG_DIR] [-n] [-mt MODEL_TYPE] [-f FORWARD_MODEL] [-i INVERSE_MODEL] [-db DATABASE] m b positional arguments: m path to output model b path to directory containing the training batches optional arguments: -h, --help show this help message and exit -p PARAMS, --params PARAMS path to the .pickle file containing the smat parameters -s S_MATS, --s-mats S_MATS path to the directory containing the smats -log LOG_DIR, --log-dir LOG_DIR path to dir where the logs are saved -n, --new train a new model -mt MODEL_TYPE, --model-type MODEL_TYPE [\"inverse\", \"forward\", \"combined\"] which kind of model to train -f FORWARD_MODEL, --forward-model FORWARD_MODEL needs to be provided when training a combined model -i INVERSE_MODEL, --inverse-model INVERSE_MODEL needs to be provided when training a combined model -db DATABASE, --database DATABASE sqlite database containing the adresses","title":"Train"},{"location":"train/#usage","text":"usage: train.py [-h] [-p PARAMS] [-s S_MATS] [-log LOG_DIR] [-n] [-mt MODEL_TYPE] [-f FORWARD_MODEL] [-i INVERSE_MODEL] [-db DATABASE] m b positional arguments: m path to output model b path to directory containing the training batches optional arguments: -h, --help show this help message and exit -p PARAMS, --params PARAMS path to the .pickle file containing the smat parameters -s S_MATS, --s-mats S_MATS path to the directory containing the smats -log LOG_DIR, --log-dir LOG_DIR path to dir where the logs are saved -n, --new train a new model -mt MODEL_TYPE, --model-type MODEL_TYPE [\"inverse\", \"forward\", \"combined\"] which kind of model to train -f FORWARD_MODEL, --forward-model FORWARD_MODEL needs to be provided when training a combined model -i INVERSE_MODEL, --inverse-model INVERSE_MODEL needs to be provided when training a combined model -db DATABASE, --database DATABASE sqlite database containing the adresses","title":"Usage"}]}